---
title: "Most Probable Next Word(s) Predictor"
author: "D. Aberra"
date: "2024-07-10"
output: ioslides_presentation
---

## Introduction
**Title:** Most Probable Next Word(s) Predictor

**Objective:** Predicting the next word based on user-input ngrams (sequence of words). 

**Internal Structure:** The prediction uses a curated corpus from Blogs, Twitter, and News sources provided by the John Hopkins University Data Science instructors at Coursera. 
The Prediction Model was trained on a combined randomly selected 10% sample from each corpus. 
Accuracy was checked on unseen vector of inputs (about 30 % the size of the training set) and found to be roughly about 10% accuracy.


## Methodology
**Method:** Markov Model Approach

Utilizes historical sequences of words (ngrams) to predict the most probable next word.
Data sourced and preprocessed from diverse textual sources.

**Implementation:** R ShinyApp developed to interactively predict next words based on user input.
Integration of text mining techniques (stemming, punctuation removal, etc.).


## User Interface

**Components:**

- Sidebar Input: Allows users to enter ngrams (sequences of words).

- Action Button: Triggers the prediction and rendering of results.

- Main Panel Outputs:Probability table showing (up to 10) top predicted words. Also renders Plot visualizing top predicted words by probability

## Slide 4: Demonstration

# Usage Scenario:

**Example:** Input "takes two" into the app.

Outputs the most probable next words with their associated probabilities.

**Visualization:**

Bar chart showing probabilities of the top 10 predicted words.

Performance:
Efficient predictions due to precomputed probabilities from the training corpus.

## Slide 5: Applications and Conclusion

**Potential Use Cases:** 
- Assistive typing applications.
- Automated text completion tools.
- Enhancing user experience in chatbots and natural language processing applications.

**Conclusion:**
- Developed an interactive tool using R Shiny and Markov models.
- Enables real-time predictions of next words based on user-provided context.

**Future Directions:**
- Enhancements in model accuracy.
- Expansion to larger datasets and additional text sources.

